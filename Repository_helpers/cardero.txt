Doing:
Continue adding base for integration testing

Upgrade eslint to 5.0.0-alpha.2

Integration testing:
  - SPEC.x-tests-common:
     - deep merged with lower priority to each RESP.x-tests OBJ
     - only merge params that are supported for each operation
  - security
     - use SPEC|OPERATION.security, SPEC.securityDefinitions
     - RESP.x-tests.TEST_NAME.[TYPE_]SEC_NAME SCHEMA|undefined|null:
        - same as PARAM_NAME but using SPEC|OPERATION.security, SPEC.securityDefinitions
     - SPEC.x-tests-common.TEST_NAME.[TYPE_]SEC_NAME
     - TEST.securities:
        - like TEST.specReqParams (query|header)
        - since it is an alternative of unions (ARR_ARR), just before request parameter generation:
           - if no security param values defined in x-tests, use none
           - if one, use this one
           - if several, pick random one
        - used on both request parameters generation and response headers
  - chaining requests:
     - any string in any SCHEMA in any test can be 'OPERATIONID.TEST_NAME.[IN_]PARAM_NAME|[TYPE_]SEC_NAME|response|headers[.VARR]'
     - it will be replaced by { const: VAL } where VAL is based on that other TEST_NAME
        - run right away (await)
     - TEST_NAME will be run before the test:
        - it is run once for each test that requires it, not once for all, i.e. tests are independent from each other
        - if it fails (or has previously failed for another test), mark the test as skipped, not failed
     - each actual test should fire its own chained requests
     - if an actual test depends on several chained requests, they are run in parallel
     - caching:
        - should requests results of some tests be cached for speedup???
        - might be a bad idea as it would create shared state???
  - should validate REST.x-tests[-common] syntax:
     - no duplicate TEST_NAME for a given OPERATION
     - avoid infinite recursions when requiring other tests with 'OPERATIONID.TEST_NAME.*'
     - check for typos in 'x-tests[-common]' key name
     - for each x-tests[-common]:
        - find corresponding param|security
        - if none, throw error
        - validate it is valid [SMALL_]SCHEMA
           - no need to merge first
  - response body parsing:
     - should still:
        - parse according to Content-Type [S]
        - default to leaving it as is (i.e. as string)
     - add parsing for x-www-url-encoded (using QUERYSTRING) as an OBJ
        - use body-parser library instead???
     - Content-Type multipart/form-data (using another library) as an OBJ
  - payloads:
     - add support for formData PARAM:
        - uses { PARAM_NAME: generatedValue, ... }
        - there can be several PARAMs of that type
        - Content-Type can only be x-www-form-urlencoded or multipart/form-data (already implemented)
        - use same stringifiers as body PARAMs
     - add PARAMs stringifiers for x-www-form-urlencoded and multipart/form-data:
        - PARAM must be an OBJ:
           - for body: [SMALL_]SCHEMA.type must be 'object'
           - for formData: it is always an OBJ
        - if formData, multipart/form-data and SMALL_SCHEMA.type 'file', add parameter filename="PARAM_NAME"
        - do not set multipart/form-data parameter Content-Type
     - [SMALL_]SCHEMA.type 'file':
        - before passing to OPENAPI-SCHEMA-TO-JSON-SCHEMA (which throws on them) should convert to:
           - if RESP.schema: 'object'
           - if PARAM: try to guess type from siblings. If cannot guess, use 'string'
  - OpenAPI conformance:
     - OPENAPI-SCHEMA-TO-JSON-SCHEMA should conver PARAM.allowEmptyValue to { minLength: 1 }
     - before OPENAPI-SCHEMA-TO-JSON-SCHEMA, should try to guess SCHEMA.type if missing by checking siblings
        - otherwise, default to 'string'
     - add OpenAPI "format"s
        - to ajv
        - to JSON-SCHEMA-FAKER
  - should run NUM it() in parallel
     - NUM = OPTS.maxParallel / OPTS.repeat
     - in different microloops (for async parallelism)
     - in different processes (for CPU parallelism) (not as important)
     - maybe switch to ava to get that
  - RESP.x-tests and SPEC.x-tests-common should be cleaned|removed from the OpenAPI specifications served either from the static
    server or from the API documentation
  - how to specify "not existing model id"???
  - add fuzzy testing values???
     - maybe propose as an option to JSON-SCHEMA-FAKER???
  - during stopServer(), should delete database
  - also test middleware (not endpoints)
  - how to test a parameter like "order_by"???
  - Explore:
     - data-driven tests
     - test runners, reporting
     - fuzzy testing
     - stress testing
     - load testing
     - test coverage
  - future features:
     - To improve???
        - reduce amount of mocking needed by users
        - reduce amount of setup and teardown (e.g. starting server) needed by users
     - better way to set configuration and options
     - pass options to underlying test runner, e.g. reporters, reporting options, include|exclude, etc.
        - all those concerns should be offloaded to the test runner
     - add support for schemes:
        - use both SPEC.schemes and OPERATION.schemes
        - one test per scheme
        - ws[s]:
     - add support for OAuth2
     - add support for OpenAPI 3.0, RAML, API blueprint
     - JSON schema v7:
        - allow v7 in OpenAPI SCHEMA
        - problems:
           - not supported by OpenAPI yet
              - i.e. should be prefixed with x-*
              - should then converted by OPENAPI-SCHEMA-TO-JSON-SCHEMA (and inverse). Do a PR.
           - does not work with JSON-SCHEMA-FAKER yet
     - cancel other sub-tests once one sub-test failed:
        - including HTTP request using AbortController:
           - not supported by node-fetch yet: https://github.com/bitinn/node-fetch/pull/437
        - including writing request bodies and reading response bodies (abort STREAMs)

To do:
  - integration testing
  - fix Snyk vulnerability
  - Gulp buildwatch crashes (does not watch anymore) after the first OpenAPI error
  - clearly mark which libraries are the blockers for OpenAPI 3.0
  - use declarative way (with JSON-SCHEMA-MOCKER) instead of current approach for populating scripts
  - Node 10
  - 404 are HTML even in JSON
  - fix configuration, it's a little messy
     - implies learning about configuration tools first
  - add Flow
  - RSS/Atom
  - generate client SDKs from OpenAPI: JavaScript, Bash, others
  - update API documentation to Widdershins
  - replace current dependency REQUEST by CROSS-FETCH
  - lint-staged currently does not allow committing only half of a file
  - create fake|test database from OpenAPI:
     - can maybe specify in OpenAPI if a specific type of data is prefered
        - e.g. at least one user should be admin
        - can use faker, etc.
     - can replace populating scripts
     - can be merged with the test populating task at beginning of integration tests
  - use JSON schema instead of joi:
     - probably using SWAY.validateRequest|Response()
     - first use JSON schema during integration testing, then suggesting merging
        - maybe use enjoi as transition
     - possible advantages of JSON schemas:
        - declarative:
           - can be communicated to clients so they can validate before sending to APIs
              - there are even library to generate <form> and <input>
           - schema is data not code, i.e. easier to manipulate for other purpose
              - e.g. can be used for auto-documentation
        - we do not want to be loose on validation with sanitization, but fail hard instead
           - joi is built as sanitizer, e.g. every validation creates a deep copy
        - not JavaScript-specific
        - https://github.com/icebob/validator-benchmark
     - also validate response
     - also parse request parameters
  - replace server-driven populating by client-driven populating:
     - first refactor populating so that each route declaratively specify which models to populate instead of
       doing it imperatively
     - then let clients decide it with a query parameter instead of declaring it on the routes
     - same for:
       - filter
       - aggregation
       - pagination
       - sorting
       - population
  - generate Mongoose models from OpenAPI specification
  - add GraphQL:
     - swagger-to-graphql would allow automating it while still supporting REST
     - I estimated it at 2 days of work
  - other possible uses of OpenAPI:
     - server-side routing
     - web automation
     - mock server
  - yamllint

To do (front-end app):
  - keep .editorconfig in sync with back-end one

Ideas:
  - gamification:
     - simple overall/aggregate ranking number
     - widget/badges showing "certified by"
     - rankings, "best of the week"
     - think of potentialpark

Tools to update:
  - MongoDB, mongoose
  - nvm
  - cors
  - helmet
  - moment
  - morgan
  - winston, winston-mongodb, winston-sentry
  - lodash

Tools to learn (high priority):
  - Flow (they mentioned adding it):
     - maybe also TypeScript
     - go through to_learn to check related projects too
  - Heroku
  - Circle CI
  - ElasticSearch
  - documentation, static website generation (for API doc generation)
  - web security:
     - snyk

Tools to learn (priority):
  - yarn
  - Sentry
  - HTTPS
  - Mailgun
  - Twilio
  - Stripe

Tools to learn:
  - dotenv, nconf
  - express-rate-limit
  - express-useragent
  - geoip-lite
  - libphonenumber-js
  - husky, lint-staged
