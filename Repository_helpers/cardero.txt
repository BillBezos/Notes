Upgrade:
  - eslint 5.0.0-alpha.3

Integration testing:
  - default value for opts.tests
  - print header|body value on requiredness validation
  - yargs seems to expand globbing by itself: fix that
     - it actually is Bash expansion
  - breakpoint through all thing again
  - allow test option to be a directory searched recursively
     - also exclude option
     - running only specific tests like test.only()??? Skip some???
     - bail???
  - security:
     - security and security definitions should only be treated as possible request parameters
        - i.e. like consumes and produces
        - should be required false
        - security ARR_ARR should be flattened and duplicate removed (alternatives is useless)
        - apiKey should be type string
        - everything done during spec normalization, remove everything else including secChoices and test.request.security
     - still write that authentication is an open question that might be solved later???
  - Deps just before each repeated test run:
     - create depsInfo { resolved {}, ancestors [] } (only if top-level in recursion)
     - find all unique dependent tests ('depKeys')
     - if some are already in depsInfo.ancestors, throw infinite recursion error (error message should print the cycle)
        - otherwise add current to ancestors (by copy)
     - for each dependent test:
        - depsInfo.resolved['OperationId.TestName']:
           - if undefined, call that test (should return parameters, response and response headers), and set its promise
              - do it by reference so concurrent requests can share information (if they belong to same top-level test)
           - if defined, use it instead directly
           - depsInfo should be different for each top-level test, i.e. no sharing of info between them
     - await all dependent promises (using Promise.all())
     - if any promise was rejected, skip current test (as opposed to making it fail)
     - use those values to replace (by copy) current test.*, using TEST.deps information (and Lodash set())
        - remember OperationId, TestName, parameter name, response headers name can contain dots
     - think of case-insensitiviy for response header names and parameter names
        - but not for body properties and deep properties
  - case sensitivity:
     - matching test.request.* and response.headers.* to OpenAPI: case insensitive
     - JSON schema object properties (including body): keep case of test.* and OpenAPI
     - error messages: use the case of OpenAPI
     - parameter generation: use the case of OpenAPI
     - response headers validation: case insensitive
     - depPath: case insensitive but only the requet parameters name and response headers name
  - content negotiation:
     - Content-Type [C]:
        - should not be sent if generated request body is undefined
     - Accept [C]:
        - keep as is
     - Content-Type [S]:
        - validate that it is present or absent according to typeIs.hasBody() (i.e. revert previous commit about it)
     - Accept [S]:
        - remove from both test-openapi and api-service
  - JSON-SCHEMA-FAKER issues:
     - minItems not working???
     - not: { type: ['null', 'boolean'] } sometimes generating null???
  - validation:
     - use a -- dry option:
        - i.e. does everything but stops just before the actual fetch call
           - what about depReturns then???
        - no validate command
        - no run command, only use one command, i.e. no yargs.command()
        - no validation preliminary step. Instead throw errors where the error arises.
        - use it by api-service on gulp build
     - throw custom errors, using a common utility like autoserver
        - have a well-defined error format, including:
           - error.type
           - error.testPath
           - error.specPath
     - top-level CLI error handler should distinguish between bugs and validation errors:
        - do it by checking thrown Error type
        - if bug, should:
           - report it as such in error message
           - print stack trace
           - ask for people to fill in an issue
     - validate:
        - is OBJ
        - at least one test
        - `operationId.testName`
        - only known properties, e.g. request|response
        - corresponding PARAM_NAME|SEC_NAME and response headers exists
        - valid JSON schemas v4
        - response.status is:
           - an integer from 100-599
           - among possible status codes for that operation (parsing enum|minimum|etc.)
        - Deps point to existing `operationId.testName`
        - just after Deps has been replaced, validates TEST's schemas values are valid JSON schema v4
        - testOpts value
        - if required true, cannot be 'type' 'null' or ['null', ...]
        - input (options)
        - OpenAPI specification input
  - improve AJV-ERRORS with better error messages (e.g. for const|enum)
     - remove the few places that currently do that manually
  - test running:
     - should run NUM it() in parallel
        - NUM = OPTS.maxParallel / OPTS.repeat
        - in different microloops (for async parallelism)
        - in different processes (for CPU parallelism) (not as important)
        - maybe switch to ava to get that
        - should stop on failure if OPTS.stopOnFail true (def)
     - pass options to underlying test runner, e.g. reporters, reporting options, include|exclude, etc.
        - all those concerns should be offloaded to the test runner
        - maybe add OPTS.runner to choose between different runners (i.e. they would be adapters)
        - maybe force a specific runner???
        - maybe only allow specific runner options???
        - maybe force output to TAP format to allow different reporters???
     - probably:
        - use library to maintain NUM workers, where NUM is number of CPU cores
        - assign equal number of it() to each
           - they each spawn the same test file, but with a modulo to filter which tests they define
        - force a specific test runner:
           - should allow concurrent tests to have a maxParallel limit
           - should have lots of features, which should be directly accessible (and whitelisted) from user perspective
           - should report in TAP format, and add --reporter=MODULE option that points to tap reporter
        - do I even need a test runner??? Main things I would use it for are:
           - reporters (but could use TAP format)
           - test REGEX selection
           - parallelism
  - connect to CI
  - response body parsing:
     - should still:
        - parse according to Content-Type [S]
        - default to leaving it as is (i.e. as string)
     - add parsing for x-www-url-encoded (using QUERYSTRING) as an OBJ
        - use body-parser library instead???
     - Content-Type multipart/form-data (using another library) as an OBJ
  - payloads:
     - add support for formData PARAM:
        - uses { PARAM_NAME: generatedValue, ... }
        - there can be several PARAMs of that type
        - Content-Type can only be x-www-form-urlencoded or multipart/form-data (already implemented)
        - use same stringifiers as body PARAMs
     - add PARAMs stringifiers for x-www-form-urlencoded and multipart/form-data:
        - PARAM must be an OBJ:
           - for body: [SMALL_]SCHEMA.type must be 'object'
           - for formData: it is always an OBJ
        - if formData, multipart/form-data and SMALL_SCHEMA.type 'file', add parameter filename="PARAM_NAME"
        - do not set multipart/form-data parameter Content-Type
     - [SMALL_]SCHEMA.type 'file':
        - before passing to OPENAPI-SCHEMA-TO-JSON-SCHEMA (which throws on them) should convert to:
           - if RESP.schema.type 'object'
           - if PARAM: try to guess type from siblings. If cannot guess, use 'string'
  - OpenAPI conformance:
     - add support for PARAM.allowEmptyValue in parameter generation
     - add OpenAPI "format"s
        - to ajv
        - to JSON-SCHEMA-FAKER
  - add fuzzy testing values???
     - maybe propose as an option to JSON-SCHEMA-FAKER???
  - during stopServer(), should delete database
  - also test middleware (not endpoints)
  - timeout might be too high to detect actual timeouts
     - maybe add timeouts to fetch() but not to tests
  - add support for $data in x-tests JSON schemas
     - should be able to target merged response body, response headers, request
       parameters and security
  - should Accept [C|S] be required???
  - Explore:
     - test runners, reporting
     - fuzzy testing
     - stress testing
     - load testing
     - test coverage
  - To improve???
     - reduce amount of mocking needed by users
     - reduce amount of setup and teardown (e.g. starting server) needed by users
  - better way to set configuration and options
  - produce code coverage report
  - divide repository into smaller modules: request building, response validation, etc.
  - schemes:
     - support over protocols than HTTP
        - including WebSocket
     - support OPERATION.schemes
     - unless OPTS.endpoint was given, should randomly pick protocol among SPEC|OPERATION.schemes for each test
  - security:
     - add support for HTTP authentication
     - add support for OAuth2
  - add support for OpenAPI 3.0
  - add support for RAML, API blueprint
  - load test file re-using same logic as autoserver to allow many formats ("autoformat")
     - should validate against circular references, but by adding this as a feature to autoformat
  - dynamic properties keys:
     - problematic on parameter generation and response validation
        - for parameter name, response header names, OpenAPI schema properties
        - OpenAPI only allows static keys
     - possible solution:
        - use 'REGEXP' for keys
        - transform to patternProperties instead of properties
           - both ajv and JSON-SCHEMA-FAKER should then handle it correctly
        - how to mark that a key is a REGEXP not a STR??? Possible solutions:
           - all keys are REGEXPs
           - "/.../" key
           - global OPT
           - testOpt
           - property in specification, e.g. x-*
        - need to work with other specification formats too
  - add configuration file and logic:
     - re-use same logic as autoserver
  - check autoserver for feature suggestions:
     - including special linting tool
  - JSON schema v7:
     - allow v7 in OpenAPI SCHEMA
     - problems:
        - not supported by OpenAPI yet, i.e. OPENAPI-SCHEMA-TO-JSON-SCHEMA outputs JSON schema v4, but this is not a problem
        - however does not work with JSON-SCHEMA-FAKER yet
  - cancel other sub-tests once one sub-test failed:
     - including HTTP request using AbortController:
        - not supported by node-fetch yet: https://github.com/bitinn/node-fetch/pull/437
     - including writing request bodies and reading response bodies (abort STREAMs)
  - allow [SMALL_]SCHEMA.x-validate:
     - custom validation similar to autoserver's
     - needs to be added to AJV
     - problem with JSON-SCHEMA-FAKER:
        - not supported as is
        - might be even harder when it comes to combining with not|allOf|anyOf|oneOf

To do:
  - upgrade:
     - eslint 5.0.0-alpha.3
  - integration testing
  - fix Snyk vulnerability
  - Gulp buildwatch crashes (does not watch anymore) after the first OpenAPI error
  - OpenAPI 3.0:
     - blockers: sway, client generation libraries
  - switch Jasmine to Jest, like in front-end
  - use declarative way (with JSON-SCHEMA-MOCKER) instead of current approach for populating scripts
  - Node 10
  - 404 are HTML even in JSON
  - fix configuration, it's a little messy
     - implies learning about configuration tools first
  - add Flow
  - RSS/Atom
  - generate client SDKs from OpenAPI: JavaScript, Bash, others
  - update API documentation to Widdershins
  - replace current dependency REQUEST by CROSS-FETCH
  - lint-staged currently does not allow committing only half of a file
  - create fake|test database from OpenAPI:
     - can maybe specify in OpenAPI if a specific type of data is prefered
        - e.g. at least one user should be admin
        - can use faker, etc.
     - can replace populating scripts
     - can be merged with the test populating task at beginning of integration tests
  - use JSON schema instead of joi:
     - probably using SWAY.validateRequest|Response()
     - first use JSON schema during integration testing, then suggesting merging
        - maybe use enjoi as transition
     - possible advantages of JSON schemas:
        - declarative:
           - can be communicated to clients so they can validate before sending to APIs
              - there are even library to generate <form> and <input>
           - schema is data not code, i.e. easier to manipulate for other purpose
              - e.g. can be used for auto-documentation
        - we do not want to be loose on validation with sanitization, but fail hard instead
           - joi is built as sanitizer, e.g. every validation creates a deep copy
        - not JavaScript-specific
        - https://github.com/icebob/validator-benchmark
     - also validate response
     - also parse request parameters
  - replace server-driven populating by client-driven populating:
     - first refactor populating so that each route declaratively specify which models to populate instead of
       doing it imperatively
     - then let clients decide it with a query parameter instead of declaring it on the routes
     - same for:
       - filter
       - aggregation
       - pagination
       - sorting
       - population
  - generate Mongoose models from OpenAPI specification
  - add GraphQL:
     - swagger-to-graphql would allow automating it while still supporting REST
     - I estimated it at 2 days of work
  - other possible uses of OpenAPI:
     - server-side routing
     - web automation
     - mock server
  - yamllint

To do (front-end app):
  - keep .editorconfig in sync with back-end one

Ideas:
  - gamification:
     - simple overall/aggregate ranking number
     - widget/badges showing "certified by"
     - rankings, "best of the week"
     - think of potentialpark

Tools to update:
  - MongoDB, mongoose
  - nvm
  - cors
  - helmet
  - moment
  - morgan
  - winston, winston-mongodb, winston-sentry
  - lodash

Tools to learn (high priority):
  - Flow (they mentioned adding it):
     - maybe also TypeScript
     - go through to_learn to check related projects too
  - Heroku
  - Circle CI
  - ElasticSearch
  - documentation, static website generation (for API doc generation)
  - web security:
     - snyk

Tools to learn (priority):
  - yarn
  - Sentry
  - HTTPS
  - Mailgun
  - Twilio
  - Stripe

Tools to learn:
  - dotenv, nconf
  - express-rate-limit
  - express-useragent
  - geoip-lite
  - libphonenumber-js
  - husky, lint-staged
