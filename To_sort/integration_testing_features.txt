Plugins:
  - use `config` to know which plugin to load
     - use CONFIG.plugins list
     - require("../plugins/PLUGIN")
        - add a TODO note that it should be replaced by require("test-openapi-plugin-PLUGIN")
        - if throws, catch it and set message "Plugin PLUGIN is used in configuration but is not installed"
     - once all loaded, find all PLUGIN.overrides and remove them from list
  - validate exported PLUGINs with a JSON schema, just after requiring them (consider it a "bug")
  - add `complete` and `end` handlers
  - reorganize plugins.js into its own folder

Final response:
  - for a given repeated task, if any plugin throws:
     - it should not run following plugins for that repeated task
     - but other repeated tasks should still run
  - wrap with an error handler each repeated task so it either:
     - returns { task } on success
     - returns (not throw) { error } on exception
 - CONF.repeat plugins:
     - sets { tasks, errors } with all of them
     - sets { task, error } with first of them (undefined if none)
     - pass both to second set of plugins, i.e. they do not have to be repeat-aware but can be (depending on whether they use plural or singular properties)
     - but return only singular version to final return value (i.e. only one result per task).
  - then run a second set of plugins, after the main one:
      - includes the reporters
      - i.e. they run even if one main plugin threw
      - they are not affected by CONF.repeat, i.e. only run once per task
      - they can throw themselves, giving same result as if task failed (i.e. returning { error })
      - they can change { task[s]|error[s] } (although we do not need it at the moment)
  - top-level command should return PROMISE:
      - resolving to ARR of  { type: 'task', ...TASK_OBJ }
      - or rejecting to ERROR with ERROR.errors OBJ_ARR
  - afterAll() cannot change tasks OBJ_ARR (because they might have alreadt been streamed) but it can return other properties that are shallowly merged
  - CLI should:
      - set exit code 1 if PROMISE was rejected
      - print error and its tack trace if PROMISE was rejected with a "bug" error
      - what if it throws???
  - bail behavior???

Reporting:
  - do not use any test runner
  - should be two plugins:
      - first produces TAP
         - use own TAP producing code, combining strengths of supertap and tape
         - do it on beforeAll() (TAP version, unique test), afterEach() (assertion), afterAll() (plan, closing comments, closing the stream)
         - should build title there
      - second uses TAP consuming libraries to perform many different reporting
         - including printing TAP as is
         - pipe to CONF.reporter.format:
             - true (def): stdout
             - false: silent
             - "PATH": file
         - CONF.reporter.style "REPORTER"
            - hand picked set of best TAP reporters for each category
            - are separate plugins, i.e. "REPORTER" is just plugin name, looked up in node modules
                - reporters have different API than other plugins, and are called from the main reporting plugin
            - also CONF.reporter.options OBJ
            - create our own best TAP reporter specialized for our purposes
               - progress bar
            - create our own JSON|YAML reporter
               - uses autoformat
               - same data as what the return value would be
  - allow tests GLOB to be "-" to refer to stdin???
  - TAP output:
     - should probably include options (like repeat, maxParallel) as final comments (so they are printed but only once)
     - should use YAML props (includes expected|actual) for errors
     - reporters should use error.request|response
        - e.g. our default reporter should:
           - show "Request was:...
           - first show "Response was:..." if response body or header validation error (include emptiness check)

CLI options:
  - get all possible plugins using readdir list from plugins dir
      - add TODO to use node_modules instead
  - then require all plugins
  - build CLI options descriptions using PLUGIN.conf.general|task.description|default|schema.type|required|others? and PLUGIN.conf.examples
  - think of type "object" and "array"
  - check code from autoserver
  - default value should be appended to description instead of using yargs.default()
  - task options should be added as an option under task category but throw error during parsing. An explanation at beginning of --help should explain how task options work

Enforce plugins separation by filter conf|task.* input and output to plugin.dependencies

Skip/only:
  - should be a plugin
  - skip has priority over only
  - TASK.skip|only BOOL
  - CONF.skip|only "GLOB"[_ARR]
      - same as setting TASK.skip|only true on test whose key matches GLOB
      - not applied on TASKs where TASK.skip|only is explicitely false
  - "only" filters tasks out in beforeAll(), i.e. not reported
  - "skip" throws at beginning of each task, setting ERROR.skipped true
       - TAP reporter mark this as # SKIP

Should add headers added by default by node-fetch to returnValue.request.*???

Support collectionFormat `multi` on query parameter serialization

Fix README.md

Fix api-service

Fix this doc with new names (e.g. "task" instead of test)

Test running:
  - should run NUM it() in parallel
     - def maxParallel should be 100
     - NUM = OPTS.maxParallel / OPTS.repeat
     - in different microloops (for async parallelism)
     - in different processes (for CPU parallelism) (not as important)
     - maybe switch to ava to get that
     - should stop on failure if OPTS.stopOnFail true (def)
  - pass options to underlying test runner, e.g. reporters, reporting options, include|exclude, etc.
     - all those concerns should be offloaded to the test runner
     - maybe add OPTS.runner to choose between different runners (i.e. they would be adapters)
     - maybe force a specific runner???
     - maybe only allow specific runner options???
     - maybe force output to TAP format to allow different reporters???
  - probably:
     - use library to maintain NUM workers, where NUM is number of CPU cores
     - assign equal number of it() to each
        - they each spawn the same test file, but with a modulo to filter which tests they define
     - force a specific test runner:
        - should allow concurrent tests to have a maxParallel limit
        - should have lots of features, which should be directly accessible (and whitelisted) from user perspective
        - should report in TAP format, and add --reporter=MODULE option that points to tap reporter
  - things I might need the test runner for:
     - reporters
     - test REGEX selection
     - parallelism
     - allow test option to be a directory searched recursively
     - exclude option
     - test.only() and test.skip()
     - bail
  - --dry:
     - when --dry, should not show any reporter output
     - but should print the first thrown error.message

Custom properties:
  - config|tasks|task.x-*
  - are simply ignored

Content negotiation:
  - autoformat
     - use it in stringify/parse
     - add multipart/form-data format:
        - parsed as { "VAR[;filename=FILE][;content-type=MIME]": VAL, ... }
        - stringify not on plain object should throw
        - each VAL is parsed according to that MIME, or left as unparsed string otherwise
     - should maybe default to raw format instead of throwing exception
  - Content-Type [C]:
     - intersection of:
        - types supported by library (for serialization)
        - merge (override) of:
           - def: application/json
           - spec.consumes
           - test.request.headers.content-type
              - matched case-insensitive
              - if specified, must only use:
                 - type 'string'
                 - enum
                 - default|title|description
     - intersection:
        - if empty array, throw that MIME is unsupported
        - should work with MIMEs being just '+EXT'
        - MIME options:
           - if none specified, leave as is
           - if specified by one side or both sides and equal, pick it
           - if specified by both sides and different, do not pick that MIME
  - Accept [C]:
     - same but with:
        - types supported by library (for parsing)
        - def: any
        - spec.produces
        - test.request.headers.accept
  - Content-Type [S]
     - if not among possible library parsers, throw error
     - used to pick how to parse body
     - def: application/octet-stream
     - validate according to same logic as other standard headers
  - [SMALL_]SCHEMA.type 'file':
     - PARAM:
        - during spec normalization, set Content-Type [C] to multipart/form-data
        - adds parameter filename="PARAM_NAME"
     - RESP:
        - validate Content-Type [S] is multipart/form-data
        - validates every part has "filename"
     - when normalizing OpenAPI schema to JSON schema:
        - convert to another type by guessing from other properties, and defaulting to string
        - should propose a PR to OPENAPI-SCHEMA-TO-JSON-SCHEMA (which throws at the moment)

Produce code coverage report

Add fuzzy testing values???
  - maybe propose as an option to JSON-SCHEMA-FAKER???

Also test middleware (not endpoints)

Add support for $data in x-tests JSON schemas
  - should be able to target merged response body, response headers, request
    parameters

Explore:
  - test runners, reporting
  - fuzzy testing
  - stress testing
  - load testing
  - test coverage

To improve???
  - reduce amount of mocking needed by users
  - reduce amount of setup and teardown (e.g. starting server) needed by users
     - including faking authentication

Plugins:
  - move plugins to own repositories
  - create a repository with some core plugins already included, so users don't have to
  - remove CORE_PLUGINS array

Schemes:
  - support over protocols than HTTP
     - including WebSocket
  - support OPERATION.schemes
  - unless OPTS.endpoint was given, should randomly pick protocol among SPEC|OPERATION.schemes for each test

Think about using OpenAPI 2.0 collectionFormat or OpenAPI 3.0 styles outside of OpenAPI

Add support for HTTP authentication, OAuth2 and OpenID

Add support for OpenAPI 3.0, RAML, API blueprint
  - should use a specification abstraction layer
  - if api-elements is not good enough, create own

Re-use autoserver's ajv error beautification utility (separate it in a different module)

Load test file re-using same logic as autoserver to allow many formats ("autoformat")

Dynamic properties keys:
  - problematic on parameter generation and response validation
     - for parameter name, response header names, OpenAPI schema properties
     - OpenAPI only allows static keys
  - possible solution:
     - use 'REGEXP' for keys
     - transform to patternProperties instead of properties
        - both ajv and JSON-SCHEMA-FAKER should then handle it correctly
     - how to mark that a key is a REGEXP not a STR??? Possible solutions:
        - all keys are REGEXPs
        - "/.../" key
        - global OPT
        - testOpt
        - property in specification, e.g. x-*
     - need to work with other specification formats too

Add configuration file and logic:
  - re-use same logic as autoserver
  - including JSON references (including in task files)

Check autoserver for feature suggestions:
  - including special linting tool

JSON schema v7:
  - allow v7 in OpenAPI SCHEMA
  - problems:
     - not supported by OpenAPI yet, i.e. OPENAPI-SCHEMA-TO-JSON-SCHEMA outputs JSON schema v4, but this is not a problem
     - however does not work with JSON-SCHEMA-FAKER yet

Cancel other sub-tests once one sub-test failed:
  - including HTTP request using AbortController:
     - not supported by node-fetch yet: https://github.com/bitinn/node-fetch/pull/437
  - including writing request bodies and reading response bodies (abort STREAMs)

Allow [SMALL_]SCHEMA.x-validate:
  - custom validation similar to autoserver's
  - needs to be added to AJV
  - problem with JSON-SCHEMA-FAKER:
     - not supported as is
     - might be even harder when it comes to combining with not|allOf|anyOf|oneOf

autopackage:
  - abtraction of package.json for many programming languages and OS package managers
  - automatically creates other package.json-like files
  - should whitelist the format we want,  to avoid pollution???
  - automatically publish:
     - maybe using a common user controlled by me
  - paying option:
     - to allow publishing
     - GitHub hooks

Business idea:
  - CI features:
     - executes requests on cloud/FaaS
     - notifications (GitHub hooks, etc.)
  - configuration editor
     - linting
     - execute as you type
  - nice reporting
