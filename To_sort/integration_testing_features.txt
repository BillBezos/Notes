CLI options:
  - get all possible plugins using readdir list from plugins dir
      - add TODO to use node_modules instead
  - then require all plugins
  - build CLI options descriptions using PLUGIN.conf.general|task.description|default|schema.type|required|others? and PLUGIN.conf.examples
  - think of type "object" and "array"
  - check code from autoserver
  - default value should be appended to description instead of using yargs.default()
  - task options should be added as an option under task category but throw error during parsing. An explanation at beginning of --help should explain how task options work
  - should work with dynamic options like config.report.options.* but still be strict enough to validate typos

config.maxParallel:
  - max number of tasks at once
  - def 100
  - buffered in the beginning of runTask, i.e.:
     - depReqs count as one task
     - repeated tasks each count as one task

CPU parallelism:
  - run tasks in several worker processes
  - only for 'run' handlers
     - 'start', 'complete' and 'end' are run in master process
        - we need 'complete' handlers in same process because they are stateful,
          e.g. tasks ordering, TAP index incrementing, progress bar, etc.
  - check async to_learn for inspiration
  - should respect maxParallel
  - should allow sending to remote worker, i.e. allowing fleet of remote worker
     - should allow sending to FaaS
  - plugin.start|end() must be run once on each child process. Reason:
     - return value of plugin.start() might not be JSON serializable
     - if plugin.start() open a socket, we want it to be on the remote worker if the child process is a remote worker
  - handle when child process crashes or is not reachable anymore???
  - config, tasks, thrown error properties and new task props should be JSON serializable (for IPC)
      - also it ensures reporting matches return values
  - probably cannot pass simply the task:
      - some plugins require network connection from start handler, runTask() or list of plugins, none of which are JSON serializable
      - i.e. probably need to fork() whole project or part of it
          - including start|end handlers and pligins load
          - report plugin could be done only on master
  - child processes should return each task one by one (i.e. stream) not all at once when done
  - should tasks input be passed from master to children one by one or all at once???
      - one by one: can send to workers with the smallest load
           - send some extra tasks as buffer to avoid idle workers waiting for new task???
      - all at once: fastest to communicate tasks
  - load config and tasks files in master???

Custom properties:
  - config|tasks|task.x-*
  - are simply ignored

Should add headers added by default by node-fetch to rawRequest

Content negotiation:
  - autoformat
     - use it in stringify/parse
     - add multipart/form-data format:
        - parsed as { "VAR[;filename=FILE][;content-type=MIME]": VAL, ... }
        - stringify not on plain object should throw
        - each VAL is parsed according to that MIME, or left as unparsed string otherwise
     - should maybe default to raw format instead of throwing exception
  - Content-Type [C]:
     - intersection of:
        - types supported by library (for serialization)
        - arrays merge (in priority order) of:
           - task.call.headers.content-type
              - matched case-insensitive
              - if specified, must only use:
                 - type 'string'
                 - enum
                 - default|title|description
           - spec.consumes
           - def: application/json
     - intersection:
        - if empty array, throw that MIME is unsupported
        - should work with MIMEs being just '+EXT'
        - MIME options:
           - if none specified, leave as is
           - if specified by one side only, pick it
           - if specified by both sides and equal, pick it
           - if specified by both sides and different, do not pick that MIME
  - Accept [C]:
     - same but with:
        - types supported by library (for parsing)
        - using:
           - task.request.headers.accept
           - spec.produces
           - def: any
  - Content-Type [S]
     - if not among possible library parsers, throw error
     - used to pick how to parse body
     - def: application/octet-stream
     - validate according to same logic as other standard headers
  - [SMALL_]SCHEMA.type 'file':
     - PARAM:
        - during spec normalization, set Content-Type [C] to multipart/form-data
        - adds parameter filename="PARAM_NAME"
     - RESP:
        - validate Content-Type [S] is multipart/form-data
        - validates every part has "filename"
     - when normalizing OpenAPI schema to JSON schema:
        - convert to another type by guessing from other properties, and defaulting to string
        - should propose a PR to OPENAPI-SCHEMA-TO-JSON-SCHEMA (which throws at the moment)

Validate:
  - custom formats
  - at the moment, ajv formats (e.g. uuid) are included by default: good idea???

Explore:
  - fuzzy testing
  - stress testing
  - load testing

To improve???
  - reduce amount of mocking needed by users
  - reduce amount of setup and teardown (e.g. starting server) needed by users
     - including faking authentication

Plugins:
  - move plugins to own repositories
  - create a repository with some core plugins already included, so users don't have to
  - remove CORE_PLUGINS array

Plugin that only execute binary or Node.js file

Schemes:
  - support over protocols than HTTP
     - including WebSocket
  - support OPERATION.schemes
  - unless OPTS.endpoint was given, should randomly pick protocol among SPEC|OPERATION.schemes for each task

Think about using OpenAPI 2.0 collectionFormat or OpenAPI 3.0 styles outside of OpenAPI

Add support for HTTP authentication, OAuth2 and OpenID

Add support for OpenAPI 3.0, RAML, API blueprint
  - should use a specification abstraction layer
  - if api-elements is not good enough, create own

collectionFormat on formData for OpenAPI 2.0 does not currently work

Re-use autoserver's ajv error beautification utility (separate it in a different module)

Globbing:
  - go through globbing in to_learn.txt to improve current usage of globbing (e.g. in config.tasks or in 'glob' plugin)
  - allow passing directories (included recursively) to config.tasks

Reporters:
  - go through CLI doc in to_learn.txt to improve current reporters
  - try to simplify reporter.*() interface:
     - too many methods: options(), start(), tick(), complete(), end()
  - 'min' reporter:
     - replace spinner by progress bar
     - add diffs between ERROR.expected and ERROR.actual
  - 'object' reporter:
     - use autoformat
     - add a 'path' option (e.g. JSON path)
  - 'notify' reporter:
     - go through to_learn.txt for desktop notifications
     - show project icon in popup
  - add other reporters:
     - see list in my reporters doc: minimal sentence, sentence, dot, progress, nyan, plane, flat, spec, markdown, styleless
       HTML, static HTML, dynamic HTML, JSON stream, XUnit, JUnit, NUnit, Teamcity, AppVeyor
     - try to use a generic input (not test-openapi-specific) so that they can be used by other projects
        - i.e. same idea as TAP but using a stream of JavaScript objects instead of using TAP string parsing

Dynamic properties keys:
  - problematic on parameter generation and response validation
     - for parameter name, response header names, OpenAPI schema properties
     - OpenAPI only allows static keys
  - possible solution:
     - use 'REGEXP' for keys
     - transform to patternProperties instead of properties
        - both ajv and JSON-SCHEMA-FAKER should then handle it correctly
     - how to mark that a key is a REGEXP not a STR??? Possible solutions:
        - all keys are REGEXPs
        - "/.../" key
        - global OPT
        - taskOpt
        - property in specification, e.g. x-*
     - need to work with other specification formats too

Polymorphism:
  - support config|task.PLUGIN values being either an object or not
     - at the moment it does not work, e.g. when retrieving final return value

Snapshot testing:
  - persist (if not yet) response.raw string as is and check difference on next run
  - persist in a Markdown file with code blocks (i.e. can be used as documentation, and gives nice git diff)
  - automatic pruning (i.e. delete snapshot folder before writing to it)
  - what about dynamic attributes (e.g timestamps)???
  - how to update snapshots???
     - think of CI mode

Maybe: watch mode

Add configuration file and logic:
  - re-use same logic as autoserver
  - including JSON references (including in task files)
  - load task file re-using same logic as autoserver to allow many formats ("autoformat")

Check autoserver for feature suggestions:
  - including special linting tool

JSON schema v7:
  - allow v7 in OpenAPI SCHEMA
  - problems:
     - not supported by OpenAPI yet, i.e. OPENAPI-SCHEMA-TO-JSON-SCHEMA outputs JSON schema v4, but this is not a problem
     - however does not work with JSON-SCHEMA-FAKER yet

How to enforce handler arguments are read-only???
  - deepFreeze problems:
     - slow
     - some arguments might need to mutate state, e.g. streams or servers attached to task|config.*

autopackage:
  - abtraction of package.json for many programming languages and OS package managers
  - automatically creates other package.json-like files
  - should whitelist the format we want,  to avoid pollution???
  - automatically publish:
     - maybe using a common user controlled by me
  - paying option:
     - to allow publishing
     - GitHub hooks

autotask:
  - based of autovalidate
  - parallel, stateless task runner
  - as opposed to Gulp, Grunt, autotools, brunch:
     - optimized for parallelism, not sequencing
        - run an array of tasks, not a tree
        - tasks are independent
           - failure do not stop other tasks
     - stateless/functional:
        - tasks are meant to return values not modify state
           - rich and diverse reporting
        - not meant for builds
           - reporting is silent on success, verbose on failure (not the inverse)
  - also uses declarative approach
  - autovalidate:
     - simply autotask with some default plugins
     - should allow users specifying extra plugins though, including between default plugins

Business idea:
  - CI features:
     - executes requests on cloud/FaaS
     - notifications (GitHub hooks, etc.)
  - configuration editor
     - linting
     - execute as you type
  - nice reporting
